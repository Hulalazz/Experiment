\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstraction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Determinant Gradient Method}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Gradient Descent}{1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gradient Descent\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{GD}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Stochastic Gradient Descent}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Primary Stochastic Gradient Descent\relax }}{2}}
\newlabel{SGD}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Adaptive Learning Rate}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Adagrad}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Adagrad Algorithm\relax }}{3}}
\newlabel{Adagrad}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}RMSprop}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces RMSprop Algorithm\relax }}{3}}
\newlabel{RMSprop}{{4}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Adam}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Variance Reduction}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Adam\relax }}{4}}
\newlabel{Adam}{{5}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Stochastic Average Gradient}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}SVRG}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}SVRG++}{4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces SVRG\relax }}{5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces SVRG++\relax }}{5}}
\newlabel{SVRG++}{{7}{5}}
